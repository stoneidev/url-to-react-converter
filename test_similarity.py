#!/usr/bin/env python
"""
ì›¹í˜ì´ì§€ ìŠ¤í¬ë˜í•‘ í›„ ìœ ì‚¬ë„ ìë™ ê²€ì‚¬ ìŠ¤í¬ë¦½íŠ¸
"""

import asyncio
import sys
from pathlib import Path

from src.scraper import WebPageScraper
from src.similarity_checker import SimilarityChecker


async def scrape_and_check(url: str, output_name: str = "test"):
    """
    ì›¹í˜ì´ì§€ë¥¼ ìŠ¤í¬ë˜í•‘í•˜ê³  ìœ ì‚¬ë„ë¥¼ ìë™ìœ¼ë¡œ ê²€ì‚¬

    Args:
        url: ìŠ¤í¬ë˜í•‘í•  URL
        output_name: ì¶œë ¥ íŒŒì¼ëª…
    """
    print("="*70)
    print("ğŸš€ URL to React Converter - Scraping & Similarity Check")
    print("="*70)

    # 1. ì›¹í˜ì´ì§€ ìŠ¤í¬ë˜í•‘
    print(f"\nğŸ“¥ Phase 1: Scraping webpage...")
    print(f"   URL: {url}")

    scraper = WebPageScraper(output_dir="./output")
    html_path = await scraper.scrape_and_save(url, output_name)

    print(f"\nâœ… Scraping complete!")
    print(f"   HTML saved: {html_path}")
    print(f"   Assets saved: {scraper.assets_dir}")

    # 2. ìœ ì‚¬ë„ ê²€ì‚¬
    print(f"\nğŸ“Š Phase 2: Checking similarity...")

    checker = SimilarityChecker()
    result = await checker.check_similarity(url, str(html_path))

    # 3. ìƒì„¸ ë¦¬í¬íŠ¸ ì¶œë ¥
    checker.print_detailed_report(result)

    # 4. JSON ë¦¬í¬íŠ¸ ì €ì¥
    report_path = f"output/{output_name}_similarity_report.json"
    checker.save_report(result, report_path)

    # 5. ê²°ê³¼ ìš”ì•½
    print(f"\nğŸ¯ Quick Summary:")
    overall = result['overall_similarity']

    if overall >= 90:
        status = "âœ… Excellent"
        color = "ğŸŸ¢"
    elif overall >= 70:
        status = "âœ“ Good"
        color = "ğŸŸ¡"
    elif overall >= 50:
        status = "âš ï¸  Fair"
        color = "ğŸŸ "
    else:
        status = "âŒ Poor"
        color = "ğŸ”´"

    print(f"   {color} Overall Similarity: {overall}% ({status})")
    print(f"   ğŸ“„ Local HTML: {html_path}")
    print(f"   ğŸ“Š Report: {report_path}")

    print(f"\nğŸ’¡ Test the downloaded HTML:")
    print(f"   python src/server.py -d output -p 8000")
    print(f"   Then open: http://localhost:8000/{output_name}.html")

    return result


async def main():
    """CLI ë©”ì¸ í•¨ìˆ˜"""
    if len(sys.argv) < 2:
        print("Usage: python test_similarity.py <url> [output_name]")
        print("\nExamples:")
        print("  python test_similarity.py https://example.com")
        print("  python test_similarity.py https://example.com my_test")
        sys.exit(1)

    url = sys.argv[1]
    output_name = sys.argv[2] if len(sys.argv) > 2 else "test"

    try:
        await scrape_and_check(url, output_name)
    except KeyboardInterrupt:
        print(f"\n\nâš ï¸  Process interrupted by user")
        sys.exit(1)
    except Exception as e:
        print(f"\n\nâŒ Error: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    asyncio.run(main())
